{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32c4ea0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/knuvi/anaconda3/envs/yolov8/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time, datetime\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import datetime as dt\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import torch, gc\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "\n",
    "#from skimage import io\n",
    "import sklearn\n",
    "from sklearn.model_selection import GroupKFold, StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, log_loss, f1_score, confusion_matrix\n",
    "from sklearn import metrics, preprocessing\n",
    "import timm\n",
    "import albumentations as A\n",
    "import wandb"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3c83ea5a",
   "metadata": {},
   "source": [
    "##### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57c0283c",
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'seed': 42,\n",
    "    'model': 'inception_resnet_v2',\n",
    "    'img_size': 256,\n",
    "    'epochs': 200,\n",
    "    'train_bs':128,\n",
    "    'valid_bs':64,\n",
    "    'lr': 1e-4,\n",
    "    'num_workers': 10,\n",
    "    'verbose_step': 1,\n",
    "    'patience' : 5,\n",
    "    'device': 'cuda:0',\n",
    "    'freezing': False,\n",
    "    'trainable_layer': 6,\n",
    "    'model_path': './models'\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2e02c8f5",
   "metadata": {},
   "source": [
    "#### Train dataset\n",
    "##### Disaster coco: 894 // flickr: 184 // open_image: 616 // aug 6620 // generated 1782\n",
    "##### Non-disaster coco: 30000 // open_image: 30000\n",
    "---\n",
    "###### disaster, non-disaster 아래 모든 이미지를 들고 옵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7001\n"
     ]
    }
   ],
   "source": [
    "folder_path = './data/generated_images/train'\n",
    "files = os.listdir(folder_path)\n",
    "print(len(files))\n",
    "#files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the data structure\n",
    "data = {\n",
    "    'id': [],\n",
    "    'path': [],\n",
    "    'label': [],\n",
    "    'type': []  # Distinguishing between train, valid, and test\n",
    "}\n",
    "\n",
    "# Define the base directory\n",
    "base_dir = './data'\n",
    "\n",
    "# Define the subdirectories and labels\n",
    "categories = {\n",
    "    'generated_images': 'generated',\n",
    "    'natural_images': 'natural'\n",
    "}\n",
    "\n",
    "# Include 'test' in the subfolders\n",
    "subfolders = ['train', 'valid', 'test']\n",
    "\n",
    "# Function to process each directory\n",
    "def process_directory(path, label, folder_type):\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        # Only proceed if in the right subfolder\n",
    "        if os.path.basename(root) in subfolders:\n",
    "            for file in files:\n",
    "                if file.lower().endswith(('.png', '.jpg', '.jpeg')):  # Adjust for image formats as necessary\n",
    "                    data['id'].append(file)\n",
    "                    data['path'].append(os.path.join(root, file))\n",
    "                    data['label'].append(label)\n",
    "                    data['type'].append(folder_type)\n",
    "\n",
    "# Iterate through each category and its specified subdirectories\n",
    "for category, label in categories.items():\n",
    "    for subfolder in subfolders:\n",
    "        dir_path = os.path.join(base_dir, category, subfolder)\n",
    "        process_directory(dir_path, label, subfolder)\n",
    "\n",
    "# Convert the entire data to a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "le = preprocessing.LabelEncoder()\n",
    "df['label'] = le.fit_transform(df['label'].values)\n",
    "\n",
    "# Creating separate dataframes for train, valid, and test\n",
    "df_train = df[df['type'] == 'train'].reset_index(drop=True)\n",
    "df_valid = df[df['type'] == 'valid'].reset_index(drop=True)\n",
    "df_test = df[df['type'] == 'test'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>path</th>\n",
       "      <th>label</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>folder2_05076.png</td>\n",
       "      <td>./data/generated_images/valid/folder2_05076.png</td>\n",
       "      <td>0</td>\n",
       "      <td>valid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>folder2_02580.png</td>\n",
       "      <td>./data/generated_images/valid/folder2_02580.png</td>\n",
       "      <td>0</td>\n",
       "      <td>valid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>folder1_01296.png</td>\n",
       "      <td>./data/generated_images/valid/folder1_01296.png</td>\n",
       "      <td>0</td>\n",
       "      <td>valid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>folder1_04224.png</td>\n",
       "      <td>./data/generated_images/valid/folder1_04224.png</td>\n",
       "      <td>0</td>\n",
       "      <td>valid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>folder2_02295.png</td>\n",
       "      <td>./data/generated_images/valid/folder2_02295.png</td>\n",
       "      <td>0</td>\n",
       "      <td>valid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5795</th>\n",
       "      <td>000000421602.jpg</td>\n",
       "      <td>./data/natural_images/valid/000000421602.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>valid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5796</th>\n",
       "      <td>000000183435.jpg</td>\n",
       "      <td>./data/natural_images/valid/000000183435.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>valid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5797</th>\n",
       "      <td>000000133436.jpg</td>\n",
       "      <td>./data/natural_images/valid/000000133436.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>valid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5798</th>\n",
       "      <td>000000447520.jpg</td>\n",
       "      <td>./data/natural_images/valid/000000447520.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>valid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5799</th>\n",
       "      <td>000000029358.jpg</td>\n",
       "      <td>./data/natural_images/valid/000000029358.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>valid</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5800 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id                                             path  \\\n",
       "0     folder2_05076.png  ./data/generated_images/valid/folder2_05076.png   \n",
       "1     folder2_02580.png  ./data/generated_images/valid/folder2_02580.png   \n",
       "2     folder1_01296.png  ./data/generated_images/valid/folder1_01296.png   \n",
       "3     folder1_04224.png  ./data/generated_images/valid/folder1_04224.png   \n",
       "4     folder2_02295.png  ./data/generated_images/valid/folder2_02295.png   \n",
       "...                 ...                                              ...   \n",
       "5795   000000421602.jpg     ./data/natural_images/valid/000000421602.jpg   \n",
       "5796   000000183435.jpg     ./data/natural_images/valid/000000183435.jpg   \n",
       "5797   000000133436.jpg     ./data/natural_images/valid/000000133436.jpg   \n",
       "5798   000000447520.jpg     ./data/natural_images/valid/000000447520.jpg   \n",
       "5799   000000029358.jpg     ./data/natural_images/valid/000000029358.jpg   \n",
       "\n",
       "      label   type  \n",
       "0         0  valid  \n",
       "1         0  valid  \n",
       "2         0  valid  \n",
       "3         0  valid  \n",
       "4         0  valid  \n",
       "...     ...    ...  \n",
       "5795      1  valid  \n",
       "5796      1  valid  \n",
       "5797      1  valid  \n",
       "5798      1  valid  \n",
       "5799      1  valid  \n",
       "\n",
       "[5800 rows x 4 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>path</th>\n",
       "      <th>label</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>folder2_03497.png</td>\n",
       "      <td>./data/generated_images/train/folder2_03497.png</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>folder2_02183.png</td>\n",
       "      <td>./data/generated_images/train/folder2_02183.png</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>folder1_06745.png</td>\n",
       "      <td>./data/generated_images/train/folder1_06745.png</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>folder1_05603.png</td>\n",
       "      <td>./data/generated_images/train/folder1_05603.png</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>folder2_02777.png</td>\n",
       "      <td>./data/generated_images/train/folder2_02777.png</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16995</th>\n",
       "      <td>000000326064.jpg</td>\n",
       "      <td>./data/natural_images/train/000000326064.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16996</th>\n",
       "      <td>000000205000.jpg</td>\n",
       "      <td>./data/natural_images/train/000000205000.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16997</th>\n",
       "      <td>000000219739.jpg</td>\n",
       "      <td>./data/natural_images/train/000000219739.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16998</th>\n",
       "      <td>000000462164.jpg</td>\n",
       "      <td>./data/natural_images/train/000000462164.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16999</th>\n",
       "      <td>000000269788.jpg</td>\n",
       "      <td>./data/natural_images/train/000000269788.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id                                             path  \\\n",
       "0      folder2_03497.png  ./data/generated_images/train/folder2_03497.png   \n",
       "1      folder2_02183.png  ./data/generated_images/train/folder2_02183.png   \n",
       "2      folder1_06745.png  ./data/generated_images/train/folder1_06745.png   \n",
       "3      folder1_05603.png  ./data/generated_images/train/folder1_05603.png   \n",
       "4      folder2_02777.png  ./data/generated_images/train/folder2_02777.png   \n",
       "...                  ...                                              ...   \n",
       "16995   000000326064.jpg     ./data/natural_images/train/000000326064.jpg   \n",
       "16996   000000205000.jpg     ./data/natural_images/train/000000205000.jpg   \n",
       "16997   000000219739.jpg     ./data/natural_images/train/000000219739.jpg   \n",
       "16998   000000462164.jpg     ./data/natural_images/train/000000462164.jpg   \n",
       "16999   000000269788.jpg     ./data/natural_images/train/000000269788.jpg   \n",
       "\n",
       "       label   type  \n",
       "0          0  train  \n",
       "1          0  train  \n",
       "2          0  train  \n",
       "3          0  train  \n",
       "4          0  train  \n",
       "...      ...    ...  \n",
       "16995      1  train  \n",
       "16996      1  train  \n",
       "16997      1  train  \n",
       "16998      1  train  \n",
       "16999      1  train  \n",
       "\n",
       "[17000 rows x 4 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8e34f5cf",
   "metadata": {},
   "source": [
    "#### Wandb (Trainning log tracking) init, project name define "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "581a512e",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_now = dt.datetime.now()\n",
    "run_id = time_now.strftime(\"%Y%m%d%H%M\")\n",
    "project_name = 'gen_'+ 'icp_res'\n",
    "user = 'hojunking'\n",
    "run_name = project_name + '_' + run_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c454bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f5d2c6fd",
   "metadata": {},
   "source": [
    "##### All images have been augmented physically, only transform the images to be resized by 256 by 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "884eb987-4341-4fe7-8094-6e61cb051af5",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'albumentations' has no attribute 'pytorch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/knuvi/Desktop/hojun/generated_image_classifier/train.ipynb Cell 14\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B155.230.90.69/home/knuvi/Desktop/hojun/generated_image_classifier/train.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m transform_train \u001b[39m=\u001b[39m A\u001b[39m.\u001b[39mCompose(\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B155.230.90.69/home/knuvi/Desktop/hojun/generated_image_classifier/train.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m     [\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B155.230.90.69/home/knuvi/Desktop/hojun/generated_image_classifier/train.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m         A\u001b[39m.\u001b[39mResize(height \u001b[39m=\u001b[39m CFG[\u001b[39m'\u001b[39m\u001b[39mimg_size\u001b[39m\u001b[39m'\u001b[39m], width \u001b[39m=\u001b[39m CFG[\u001b[39m'\u001b[39m\u001b[39mimg_size\u001b[39m\u001b[39m'\u001b[39m]),\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B155.230.90.69/home/knuvi/Desktop/hojun/generated_image_classifier/train.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m         A\u001b[39m.\u001b[39mNormalize(mean\u001b[39m=\u001b[39m(\u001b[39m0.485\u001b[39m, \u001b[39m0.456\u001b[39m, \u001b[39m0.406\u001b[39m), std\u001b[39m=\u001b[39m(\u001b[39m0.229\u001b[39m, \u001b[39m0.224\u001b[39m, \u001b[39m0.225\u001b[39m)),\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B155.230.90.69/home/knuvi/Desktop/hojun/generated_image_classifier/train.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m         A\u001b[39m.\u001b[39;49mpytorch\u001b[39m.\u001b[39mtransforms\u001b[39m.\u001b[39mToTensorV2()\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B155.230.90.69/home/knuvi/Desktop/hojun/generated_image_classifier/train.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m         ])\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B155.230.90.69/home/knuvi/Desktop/hojun/generated_image_classifier/train.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m transform_test \u001b[39m=\u001b[39m A\u001b[39m.\u001b[39mCompose(\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B155.230.90.69/home/knuvi/Desktop/hojun/generated_image_classifier/train.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m     [\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B155.230.90.69/home/knuvi/Desktop/hojun/generated_image_classifier/train.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m         A\u001b[39m.\u001b[39mResize(height \u001b[39m=\u001b[39m CFG[\u001b[39m'\u001b[39m\u001b[39mimg_size\u001b[39m\u001b[39m'\u001b[39m], width \u001b[39m=\u001b[39m CFG[\u001b[39m'\u001b[39m\u001b[39mimg_size\u001b[39m\u001b[39m'\u001b[39m]),\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B155.230.90.69/home/knuvi/Desktop/hojun/generated_image_classifier/train.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m         A\u001b[39m.\u001b[39mNormalize(mean\u001b[39m=\u001b[39m(\u001b[39m0.485\u001b[39m, \u001b[39m0.456\u001b[39m, \u001b[39m0.406\u001b[39m), std\u001b[39m=\u001b[39m(\u001b[39m0.229\u001b[39m, \u001b[39m0.224\u001b[39m, \u001b[39m0.225\u001b[39m)),\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B155.230.90.69/home/knuvi/Desktop/hojun/generated_image_classifier/train.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m         A\u001b[39m.\u001b[39mpytorch\u001b[39m.\u001b[39mtransforms\u001b[39m.\u001b[39mToTensorV2()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B155.230.90.69/home/knuvi/Desktop/hojun/generated_image_classifier/train.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m         ])\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'albumentations' has no attribute 'pytorch'"
     ]
    }
   ],
   "source": [
    "transform = A.Compose(\n",
    "    [\n",
    "        A.Resize(height = CFG['img_size'], width = CFG['img_size']),\n",
    "        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "        A.pytorch.transforms.ToTensorV2()\n",
    "    ])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6c6e59ad",
   "metadata": {},
   "source": [
    "#### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f1561be",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, df, transform=None, output_label=True):\n",
    "        super().__init__()\n",
    "        self.df = df.reset_index(drop=True).copy()\n",
    "        self.transform = transform\n",
    "        self.output_label = output_label\n",
    "        \n",
    "        if output_label:\n",
    "            self.labels = self.df['label'].values\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "    \n",
    "    def __getitem__(self, index: int):\n",
    "        # Constructing the image path directly from the DataFrame\n",
    "        img_path = self.df.loc[index, 'path']\n",
    "        im_bgr = cv2.imread(img_path)\n",
    "        \n",
    "        # Check if image is loaded successfully\n",
    "        if im_bgr is not None:\n",
    "            img = cv2.cvtColor(im_bgr, cv2.COLOR_BGR2RGB)\n",
    "        else:\n",
    "            # If the image is not successfully loaded, create a black image of the defined size\n",
    "            img = np.zeros([CFG['img_size'], CFG['img_size'], 3], dtype=np.uint8)\n",
    "\n",
    "        # Crop the image from the center\n",
    "        min_side = min(img.shape[:2])\n",
    "        center_crop = A.Compose([\n",
    "            A.CenterCrop(height=min_side, width=min_side),  # Crop the center to the target size\n",
    "        ])\n",
    "        cropped_image = center_crop(image=img)[\"image\"]\n",
    "\n",
    "        # Apply transformations\n",
    "        if self.transform:\n",
    "            transformed_img = self.transform(image=cropped_image)['image']\n",
    "        else:\n",
    "            transformed_img = cropped_image\n",
    "        \n",
    "        # Get labels\n",
    "        if self.output_label:\n",
    "            target = self.labels[index]\n",
    "            return transformed_img, target\n",
    "        else:\n",
    "            return transformed_img\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "812ba765",
   "metadata": {},
   "source": [
    "#### Model Define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b1601bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class baseModel(nn.Module):\n",
    "    def __init__(self, model_arch, n_class=2, pretrained=False):\n",
    "        super().__init__()\n",
    "        self.model = timm.create_model(model_arch, pretrained=pretrained, num_classes=n_class)\n",
    "        # n_features = self.model.classifier.in_features\n",
    "        # self.model.classifier = nn.Linear(n_features, n_class)\n",
    "    \n",
    "    def freezing(self, freeze=False, trainable_layer=2):\n",
    "        if freeze:\n",
    "            # Freeze all parameters first\n",
    "            for param in self.model.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "            # Unfreeze the last few layers\n",
    "            if hasattr(self.model, 'features'):  # for models with 'features' block\n",
    "                for param in self.model.features[-trainable_layer:].parameters():\n",
    "                    param.requires_grad = True\n",
    "\n",
    "            if hasattr(self.model, 'classifier'):  # for models with 'classifier' block\n",
    "                for param in self.model.classifier.parameters():\n",
    "                    param.requires_grad = True \n",
    "            \n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "37bd9a51",
   "metadata": {},
   "source": [
    "##### Define Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "240e5531",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataloader(df_train, df_valid):\n",
    "    \n",
    "    train_ds = CustomDataset(df_train, transform=transform, output_label=True)\n",
    "    valid_ds = CustomDataset(df_valid, transform=transform,  output_label=True)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_ds,\n",
    "        batch_size=CFG['train_bs'],\n",
    "        pin_memory=True,\n",
    "        drop_last=False,\n",
    "        shuffle=True,\n",
    "        num_workers=CFG['num_workers'],\n",
    "    )\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        valid_ds, \n",
    "        batch_size=CFG['valid_bs'],\n",
    "        num_workers=CFG['num_workers'],\n",
    "        shuffle=False,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5014d065-a6ad-45f9-aee8-d1adb9da52b4",
   "metadata": {},
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "18d62956-1ab7-4c53-ad80-05955c3367f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(epoch, model, loss_fn, optimizer, train_loader, device, scheduler=None):\n",
    "    t = time.time()\n",
    "    model.train()  # Set model to training mode\n",
    "\n",
    "    running_loss = 0\n",
    "    image_preds_all = []\n",
    "    image_targets_all = []\n",
    "    \n",
    "    pbar = tqdm(enumerate(train_loader), total=len(train_loader))\n",
    "    for step, (imgs, image_labels) in pbar:\n",
    "        imgs, image_labels = imgs.to(device).float(), image_labels.to(device).long()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        with torch.cuda.amp.autocast():\n",
    "            image_preds = model(imgs)  # forward pass\n",
    "            loss = loss_fn(image_preds, image_labels)\n",
    "            scaler.scale(loss).backward()  # backward pass with scaled loss\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "        running_loss = 0.99 * running_loss + 0.01 * loss.item()  # update running loss\n",
    "        \n",
    "        # Update pbar description\n",
    "        pbar.set_description(f'Epoch {epoch} Loss: {running_loss:.4f}')\n",
    "        \n",
    "        image_preds_all.append(torch.argmax(image_preds, 1).detach().cpu().numpy())\n",
    "        image_targets_all.append(image_labels.detach().cpu().numpy())\n",
    "        \n",
    "    if scheduler is not None:\n",
    "        scheduler.step()\n",
    "\n",
    "    image_preds_all = np.concatenate(image_preds_all)\n",
    "    image_targets_all = np.concatenate(image_targets_all)\n",
    "    \n",
    "    accuracy = np.mean(image_preds_all == image_targets_all)\n",
    "    epoch_f1 = f1_score(image_targets_all, image_preds_all, average='macro')\n",
    "    \n",
    "    return image_preds_all, accuracy, running_loss / len(train_loader), confusion_matrix(image_targets_all, image_preds_all), epoch_f1\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fb18acac-bdc4-476d-91c3-50fd46b4f1db",
   "metadata": {},
   "source": [
    "##### Valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "28ed3ba1-8c45-4e70-b80a-5a26d11cdd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_one_epoch(epoch, model, loss_fn, val_loader, device, scheduler=None, schd_loss_update=False):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "\n",
    "    loss_sum = 0\n",
    "    image_preds_all = []\n",
    "    image_targets_all = []\n",
    "    \n",
    "    pbar = tqdm(enumerate(val_loader), total=len(val_loader))\n",
    "    with torch.no_grad():  # No gradients needed for validation\n",
    "        for step, (imgs, image_labels) in pbar:\n",
    "            imgs, image_labels = imgs.to(device).float(), image_labels.to(device).long()\n",
    "            \n",
    "            image_preds = model(imgs)  # forward pass\n",
    "            loss = loss_fn(image_preds, image_labels)  # calculate loss\n",
    "\n",
    "            # Aggregate predictions and targets for metrics calculation\n",
    "            image_preds_all.append(torch.argmax(image_preds, 1).detach().cpu().numpy())\n",
    "            image_targets_all.append(image_labels.detach().cpu().numpy())\n",
    "\n",
    "            loss_sum += loss.item() * image_labels.shape[0]  # total loss for average calculation\n",
    "            \n",
    "            # Update pbar description\n",
    "            pbar.set_description(f'Epoch {epoch} Loss: {loss_sum/((step+1) * val_loader.batch_size):.4f}')\n",
    "    \n",
    "    # Convert list of arrays to single numpy array for metric calculation\n",
    "    image_preds_all = np.concatenate(image_preds_all)\n",
    "    image_targets_all = np.concatenate(image_targets_all)\n",
    "    \n",
    "    # Calculate performance metrics\n",
    "    epoch_f1 = f1_score(image_targets_all, image_preds_all, average='macro')\n",
    "    acc = np.mean(image_preds_all == image_targets_all)\n",
    "    val_loss = loss_sum / len(image_targets_all)  # average loss\n",
    "\n",
    "    # Step the scheduler if it's based on validation loss and such option is enabled\n",
    "    if scheduler is not None and schd_loss_update:\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "    return image_preds_all, acc, val_loss, confusion_matrix(image_targets_all, image_preds_all), epoch_f1\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "253e9ae3",
   "metadata": {},
   "source": [
    "##### Define EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "77e9950b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=10, verbose=False, delta=0):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf  # Initialize this to a large number\n",
    "        self.delta = delta\n",
    "\n",
    "    def __call__(self, val_loss):\n",
    "        score = -val_loss  # Convert to a score (as lower loss is better, we negate it)\n",
    "\n",
    "        if self.verbose:\n",
    "            print(f'Validation loss: {val_loss}')\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.val_loss_min = val_loss\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "                print(f'Best validation loss: {self.val_loss_min}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.val_loss_min = val_loss  # Update the minimum validation loss\n",
    "            self.counter = 0  # Reset counter\n",
    "\n",
    "        return self.early_stop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37102a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    seed_everything(CFG['seed'])\n",
    "    \n",
    "    # WANDB TRACKER INIT\n",
    "    wandb.init(project=project_name, entity=user)\n",
    "    wandb.config.update(CFG)\n",
    "    wandb.run.name = run_name\n",
    "    wandb.define_metric(\"Train Accuracy\", step_metric=\"epoch\")\n",
    "    wandb.define_metric(\"Valid Accuracy\", step_metric=\"epoch\")\n",
    "    wandb.define_metric(\"Train Loss\", step_metric=\"epoch\")\n",
    "    wandb.define_metric(\"Valid Loss\", step_metric=\"epoch\")\n",
    "    wandb.define_metric(\"Train Macro F1 Score\", step_metric=\"epoch\")\n",
    "    wandb.define_metric(\"Valid Macro F1 Score\", step_metric=\"epoch\")\n",
    "    wandb.define_metric(\"Train-Valid Accuracy\", step_metric=\"epoch\")\n",
    "    \n",
    "    model_dir = CFG['model_path'] + '/{}'.format(run_name)\n",
    "    train_dir = df.dir.values\n",
    "    best_f1 =0.0\n",
    "    print('Model: {}'.format(CFG['model']))\n",
    "    # MAKE MODEL DIR\n",
    "    if not os.path.isdir(model_dir):\n",
    "        os.makedirs(model_dir)\n",
    "    \n",
    "    # EARLY STOPPING DEFINITION\n",
    "    early_stopping = EarlyStopping(patience=CFG[\"patience\"], verbose=True)\n",
    "\n",
    "    # DATALOADER DEFINITION\n",
    "    train_loader, val_loader = prepare_dataloader(df_train, df_valid)\n",
    "\n",
    "    # MODEL & DEVICE DEFINITION \n",
    "    device = torch.device(CFG['device'])\n",
    "    model =baseModel(CFG['model'], df_train.label.nunique(), pretrained=True)\n",
    "    \n",
    "    # MODEL FREEZING\n",
    "    #model.freezing(freeze = CFG['freezing'], trainable_layer = CFG['trainable_layer'])\n",
    "    if CFG['freezing'] ==True:\n",
    "        for name, param in model.named_parameters():\n",
    "            if param.requires_grad == True:\n",
    "                print(f\"{name}: {param.requires_grad}\")\n",
    "\n",
    "    model.to(device)\n",
    "    # MODEL DATA PARALLEL\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        model = nn.DataParallel(model)\n",
    "\n",
    "    scaler = torch.cuda.amp.GradScaler()   \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=CFG['lr'])\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, gamma=0.5, step_size=5)\n",
    "\n",
    "    # CRITERION (LOSS FUNCTION)\n",
    "    loss_tr = nn.CrossEntropyLoss().to(device) #MyCrossEntropyLoss().to(device)\n",
    "    loss_fn = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "    wandb.watch(model, loss_tr, log='all')\n",
    "    train_acc_list = []\n",
    "    train_matrix_list = []\n",
    "    train_f1_list = []\n",
    "    valid_acc_list = []\n",
    "    valid_matrix_list = []\n",
    "    valid_f1_list = []\n",
    "    \n",
    "\n",
    "    start = time.time()\n",
    "    for epoch in range(CFG['epochs']):\n",
    "        print('Epoch {}/{}'.format(epoch, CFG['epochs'] - 1))\n",
    "\n",
    "        # TRAINIG\n",
    "        train_preds_all, train_acc, train_loss, train_matrix, train_f1 = train_one_epoch(epoch, model, loss_tr,\n",
    "                                                                    optimizer, train_loader, device, scheduler=scheduler)\n",
    "        wandb.log({'Train Accuracy':train_acc, 'Train Loss' : train_loss, 'Train F1': train_f1, 'epoch' : epoch})\n",
    "\n",
    "        # VALIDATION\n",
    "        with torch.no_grad():\n",
    "            valid_preds_all, valid_acc, valid_loss, valid_matrix, valid_f1= valid_one_epoch(epoch, model, loss_fn,\n",
    "                                                                    val_loader, device, scheduler=None)\n",
    "            wandb.log({'Valid Accuracy':valid_acc, 'Valid Loss' : valid_loss, 'Valid F1': valid_f1 ,'epoch' : epoch})\n",
    "        print(f'Epoch [{epoch}], Train Loss : [{train_loss :.5f}] Val Loss : [{valid_loss :.5f}] Val F1 Score : [{valid_f1:.5f}]')\n",
    "        \n",
    "        # SAVE ALL RESULTS\n",
    "        train_acc_list.append(train_acc)\n",
    "        train_matrix_list.append(train_matrix)\n",
    "        train_f1_list.append(train_f1)\n",
    "\n",
    "        valid_acc_list.append(valid_acc)\n",
    "        valid_matrix_list.append(valid_matrix)\n",
    "        valid_f1_list.append(valid_f1)\n",
    "\n",
    "        # MODEL SAVE (THE BEST MODEL OF ALL OF FOLD PROCESS)\n",
    "        if valid_f1 > best_f1:\n",
    "            best_f1 = valid_f1\n",
    "            best_epoch = epoch\n",
    "            # SAVE WITH DATAPARARELLEL WRAPPER\n",
    "            #torch.save(model.state_dict(), (model_dir+'/{}.pth').format(CFG['model']))\n",
    "            # SAVE WITHOUT DATAPARARELLEL WRAPPER\n",
    "            torch.save(model.module.state_dict(), (model_dir+'/{}.pth').format(CFG['model']))\n",
    "\n",
    "        # EARLY STOPPING\n",
    "        stop = early_stopping(valid_f1)\n",
    "        if stop:\n",
    "            print(\"stop called\")   \n",
    "            break\n",
    "\n",
    "        end = time.time() - start\n",
    "        time_ = str(datetime.timedelta(seconds=end)).split(\".\")[0]\n",
    "        print(\"time :\", time_)\n",
    "\n",
    "        # PRINT BEST F1 SCORE MODEL OF FOLD\n",
    "        best_index = valid_f1_list.index(max(valid_f1_list))\n",
    "        print(f'Best Train Marco F1 : {train_f1_list[best_index]:.5f}')\n",
    "        print(train_matrix_list[best_index])\n",
    "        print(f'Best Valid Marco F1 : {valid_f1_list[best_index]:.5f}')\n",
    "        print(valid_matrix_list[best_index])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "58fade31-3bfc-4d71-9d57-73779368c975",
   "metadata": {},
   "source": [
    "#### Test dataset non-disaster 20000 // disaster 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "84cfa9f6-64a2-4f81-a093-714b8d4c05ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>path</th>\n",
       "      <th>label</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>folder1_01804.png</td>\n",
       "      <td>./data/generated_images/test/folder1_01804.png</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>folder1_01315.png</td>\n",
       "      <td>./data/generated_images/test/folder1_01315.png</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>folder1_03599.png</td>\n",
       "      <td>./data/generated_images/test/folder1_03599.png</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>folder2_03260.png</td>\n",
       "      <td>./data/generated_images/test/folder2_03260.png</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>folder1_02035.png</td>\n",
       "      <td>./data/generated_images/test/folder1_02035.png</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>000000531423.jpg</td>\n",
       "      <td>./data/natural_images/test/000000531423.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>000000204775.jpg</td>\n",
       "      <td>./data/natural_images/test/000000204775.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>000000412690.jpg</td>\n",
       "      <td>./data/natural_images/test/000000412690.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>000000545375.jpg</td>\n",
       "      <td>./data/natural_images/test/000000545375.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>000000334557.jpg</td>\n",
       "      <td>./data/natural_images/test/000000334557.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id                                            path  \\\n",
       "0     folder1_01804.png  ./data/generated_images/test/folder1_01804.png   \n",
       "1     folder1_01315.png  ./data/generated_images/test/folder1_01315.png   \n",
       "2     folder1_03599.png  ./data/generated_images/test/folder1_03599.png   \n",
       "3     folder2_03260.png  ./data/generated_images/test/folder2_03260.png   \n",
       "4     folder1_02035.png  ./data/generated_images/test/folder1_02035.png   \n",
       "...                 ...                                             ...   \n",
       "2995   000000531423.jpg     ./data/natural_images/test/000000531423.jpg   \n",
       "2996   000000204775.jpg     ./data/natural_images/test/000000204775.jpg   \n",
       "2997   000000412690.jpg     ./data/natural_images/test/000000412690.jpg   \n",
       "2998   000000545375.jpg     ./data/natural_images/test/000000545375.jpg   \n",
       "2999   000000334557.jpg     ./data/natural_images/test/000000334557.jpg   \n",
       "\n",
       "      label  type  \n",
       "0         0  test  \n",
       "1         0  test  \n",
       "2         0  test  \n",
       "3         0  test  \n",
       "4         0  test  \n",
       "...     ...   ...  \n",
       "2995      1  test  \n",
       "2996      1  test  \n",
       "2997      1  test  \n",
       "2998      1  test  \n",
       "2999      1  test  \n",
       "\n",
       "[3000 rows x 4 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5907038e-59c2-46f1-bdc5-ec3ed9655eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################## inference #############################\n",
    "def inference(model, data_loader, device):\n",
    "    model.eval()\n",
    "    image_preds_all = []\n",
    "    \n",
    "    pbar = tqdm(enumerate(data_loader), total=len(data_loader))\n",
    "    for step, (imgs) in pbar:\n",
    "        imgs = imgs.to(device).float()\n",
    "\n",
    "        image_preds = model(imgs)   #output = model(input)\n",
    "        image_preds_all += [torch.softmax(image_preds, 1).detach().cpu().numpy()]\n",
    "    \n",
    "    image_preds_all = np.concatenate(image_preds_all, axis=0)\n",
    "    return image_preds_all"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2a1b54ea",
   "metadata": {},
   "source": [
    "##### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1ebad47d-74a3-433f-9309-b06b5acad047",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 160/160 [00:56<00:00,  2.85it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>dir</th>\n",
       "      <th>label</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a8271e8c2fa02700.jpg</td>\n",
       "      <td>../Data/disaster/test/disaster/origin_images/o...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bb92b3c52eb018c8.jpg</td>\n",
       "      <td>../Data/disaster/test/disaster/origin_images/o...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cbf5687e145dc19f.jpg</td>\n",
       "      <td>../Data/disaster/test/disaster/origin_images/o...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54703d04c4271a5a.jpg</td>\n",
       "      <td>../Data/disaster/test/disaster/origin_images/o...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a07b85e2b03909c1.jpg</td>\n",
       "      <td>../Data/disaster/test/disaster/origin_images/o...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20395</th>\n",
       "      <td>0b61646f2795ca9b.jpg</td>\n",
       "      <td>../Data/disaster/test/non_disaster/open_images</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20396</th>\n",
       "      <td>0b16c09057d87676.jpg</td>\n",
       "      <td>../Data/disaster/test/non_disaster/open_images</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20397</th>\n",
       "      <td>07ddddad35140b20.jpg</td>\n",
       "      <td>../Data/disaster/test/non_disaster/open_images</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20398</th>\n",
       "      <td>0143bd9e146f6ded.jpg</td>\n",
       "      <td>../Data/disaster/test/non_disaster/open_images</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20399</th>\n",
       "      <td>04444bedb6351b62.jpg</td>\n",
       "      <td>../Data/disaster/test/non_disaster/open_images</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20400 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   image_id  \\\n",
       "0      a8271e8c2fa02700.jpg   \n",
       "1      bb92b3c52eb018c8.jpg   \n",
       "2      cbf5687e145dc19f.jpg   \n",
       "3      54703d04c4271a5a.jpg   \n",
       "4      a07b85e2b03909c1.jpg   \n",
       "...                     ...   \n",
       "20395  0b61646f2795ca9b.jpg   \n",
       "20396  0b16c09057d87676.jpg   \n",
       "20397  07ddddad35140b20.jpg   \n",
       "20398  0143bd9e146f6ded.jpg   \n",
       "20399  04444bedb6351b62.jpg   \n",
       "\n",
       "                                                     dir  label  pred  \n",
       "0      ../Data/disaster/test/disaster/origin_images/o...      0     1  \n",
       "1      ../Data/disaster/test/disaster/origin_images/o...      0     0  \n",
       "2      ../Data/disaster/test/disaster/origin_images/o...      0     0  \n",
       "3      ../Data/disaster/test/disaster/origin_images/o...      0     1  \n",
       "4      ../Data/disaster/test/disaster/origin_images/o...      0     0  \n",
       "...                                                  ...    ...   ...  \n",
       "20395     ../Data/disaster/test/non_disaster/open_images      1     1  \n",
       "20396     ../Data/disaster/test/non_disaster/open_images      1     1  \n",
       "20397     ../Data/disaster/test/non_disaster/open_images      1     1  \n",
       "20398     ../Data/disaster/test/non_disaster/open_images      1     1  \n",
       "20399     ../Data/disaster/test/non_disaster/open_images      1     1  \n",
       "\n",
       "[20400 rows x 4 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RUN INFERENCE\n",
    "model = baseModel(CFG['model'], df_test.label.nunique(), pretrained=True)\n",
    "load_model = CFG['model_path'] + '/disaster_icp_res_202307080058/' + CFG['model'] + '.pth'\n",
    "test_dir = df_test.dir.values\n",
    "\n",
    "tst_ds = CustomDataset(df_test, test_dir, transform=transform, output_label=False)\n",
    "tst_loader = torch.utils.data.DataLoader(\n",
    "    tst_ds, \n",
    "    batch_size=CFG['train_bs'],\n",
    "    num_workers=CFG['num_workers'],\n",
    "    shuffle=False,\n",
    "    pin_memory=True\n",
    ")\n",
    "device = torch.device(CFG['device'])\n",
    "\n",
    "#INFERENCE VIA MULTI-GPU\n",
    "if torch.cuda.device_count() > 1:\n",
    "        model = nn.DataParallel(model)\n",
    "model.to(device)\n",
    "\n",
    "# RUN INFERENCE\n",
    "predictions = []\n",
    "model.load_state_dict(torch.load(load_model))\n",
    "with torch.no_grad():\n",
    "    predictions += [inference(model, tst_loader, device)]\n",
    "\n",
    "\n",
    "predictions = np.mean(predictions, axis=0) \n",
    "df_test['pred'] = np.argmax(predictions, axis=1)\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "12a02ab0-d48f-4a27-bbb5-c9e7922f5e44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>dir</th>\n",
       "      <th>label</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a8271e8c2fa02700.jpg</td>\n",
       "      <td>../Data/disaster/test/disaster/origin_images/o...</td>\n",
       "      <td>disaster</td>\n",
       "      <td>non_disaster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bb92b3c52eb018c8.jpg</td>\n",
       "      <td>../Data/disaster/test/disaster/origin_images/o...</td>\n",
       "      <td>disaster</td>\n",
       "      <td>disaster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cbf5687e145dc19f.jpg</td>\n",
       "      <td>../Data/disaster/test/disaster/origin_images/o...</td>\n",
       "      <td>disaster</td>\n",
       "      <td>disaster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54703d04c4271a5a.jpg</td>\n",
       "      <td>../Data/disaster/test/disaster/origin_images/o...</td>\n",
       "      <td>disaster</td>\n",
       "      <td>non_disaster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a07b85e2b03909c1.jpg</td>\n",
       "      <td>../Data/disaster/test/disaster/origin_images/o...</td>\n",
       "      <td>disaster</td>\n",
       "      <td>disaster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20395</th>\n",
       "      <td>0b61646f2795ca9b.jpg</td>\n",
       "      <td>../Data/disaster/test/non_disaster/open_images</td>\n",
       "      <td>non_disaster</td>\n",
       "      <td>non_disaster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20396</th>\n",
       "      <td>0b16c09057d87676.jpg</td>\n",
       "      <td>../Data/disaster/test/non_disaster/open_images</td>\n",
       "      <td>non_disaster</td>\n",
       "      <td>non_disaster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20397</th>\n",
       "      <td>07ddddad35140b20.jpg</td>\n",
       "      <td>../Data/disaster/test/non_disaster/open_images</td>\n",
       "      <td>non_disaster</td>\n",
       "      <td>non_disaster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20398</th>\n",
       "      <td>0143bd9e146f6ded.jpg</td>\n",
       "      <td>../Data/disaster/test/non_disaster/open_images</td>\n",
       "      <td>non_disaster</td>\n",
       "      <td>non_disaster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20399</th>\n",
       "      <td>04444bedb6351b62.jpg</td>\n",
       "      <td>../Data/disaster/test/non_disaster/open_images</td>\n",
       "      <td>non_disaster</td>\n",
       "      <td>non_disaster</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20400 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   image_id  \\\n",
       "0      a8271e8c2fa02700.jpg   \n",
       "1      bb92b3c52eb018c8.jpg   \n",
       "2      cbf5687e145dc19f.jpg   \n",
       "3      54703d04c4271a5a.jpg   \n",
       "4      a07b85e2b03909c1.jpg   \n",
       "...                     ...   \n",
       "20395  0b61646f2795ca9b.jpg   \n",
       "20396  0b16c09057d87676.jpg   \n",
       "20397  07ddddad35140b20.jpg   \n",
       "20398  0143bd9e146f6ded.jpg   \n",
       "20399  04444bedb6351b62.jpg   \n",
       "\n",
       "                                                     dir         label  \\\n",
       "0      ../Data/disaster/test/disaster/origin_images/o...      disaster   \n",
       "1      ../Data/disaster/test/disaster/origin_images/o...      disaster   \n",
       "2      ../Data/disaster/test/disaster/origin_images/o...      disaster   \n",
       "3      ../Data/disaster/test/disaster/origin_images/o...      disaster   \n",
       "4      ../Data/disaster/test/disaster/origin_images/o...      disaster   \n",
       "...                                                  ...           ...   \n",
       "20395     ../Data/disaster/test/non_disaster/open_images  non_disaster   \n",
       "20396     ../Data/disaster/test/non_disaster/open_images  non_disaster   \n",
       "20397     ../Data/disaster/test/non_disaster/open_images  non_disaster   \n",
       "20398     ../Data/disaster/test/non_disaster/open_images  non_disaster   \n",
       "20399     ../Data/disaster/test/non_disaster/open_images  non_disaster   \n",
       "\n",
       "               pred  \n",
       "0      non_disaster  \n",
       "1          disaster  \n",
       "2          disaster  \n",
       "3      non_disaster  \n",
       "4          disaster  \n",
       "...             ...  \n",
       "20395  non_disaster  \n",
       "20396  non_disaster  \n",
       "20397  non_disaster  \n",
       "20398  non_disaster  \n",
       "20399  non_disaster  \n",
       "\n",
       "[20400 rows x 4 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Decode labels & Predictions\n",
    "df_test['label'] = le.inverse_transform(df_test['label'].values)\n",
    "df_test['pred'] = le.inverse_transform(df_test['pred'].values)\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dce5fb6e-174b-4276-bccb-4499b004243c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9915\n",
      "f1_score: 0.8912\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "test_acc = np.sum(df_test.label == df_test.pred) / len(df_test)\n",
    "test_matrix = confusion_matrix(df_test['label'], df_test['pred'])\n",
    "epoch_f1 = f1_score(df_test['label'], df_test['pred'], average='macro')\n",
    "print(f'accuracy: {test_acc:.4f}')\n",
    "print(f'f1_score: {epoch_f1:.4f}')\n",
    "\n",
    "test_matrix = confusion_matrix(df_test['label'], df_test['pred'], normalize='true')\n",
    "#test_matrix = confusion_matrix(test['label'], test['pred'])\n",
    "\n",
    "plt.figure(figsize = (15,10))\n",
    "sns.heatmap(test_matrix, \n",
    "            annot=True, \n",
    "            xticklabels = sorted(set(df_test['label'])), \n",
    "            yticklabels = sorted(set(df_test['label'])),\n",
    "            )\n",
    "plt.title('Normalized Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "#print(f'confusion_matrix \\n-------------------------\\n {test_matrix}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "32c4ea0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time, datetime\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import datetime as dt\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import torch, gc\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#from skimage import io\n",
    "from sklearn.metrics import roc_auc_score, log_loss, f1_score, confusion_matrix\n",
    "from sklearn import metrics, preprocessing\n",
    "import timm\n",
    "import albumentations as A\n",
    "import albumentations.pytorch\n",
    "import wandb"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3c83ea5a",
   "metadata": {},
   "source": [
    "##### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "57c0283c",
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'seed': 42,\n",
    "    'model': 'resnet50',\n",
    "    'img_size': 256,\n",
    "    'epochs': 200,\n",
    "    'train_bs':128,\n",
    "    'valid_bs':64,\n",
    "    'lr': 1e-4,\n",
    "    'num_workers': 10,\n",
    "    'verbose_step': 1,\n",
    "    'patience' : 5,\n",
    "    'device': 'cuda:0',\n",
    "    'freezing': False,\n",
    "    'trainable_layer': 6,\n",
    "    'model_path': './models'\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2e02c8f5",
   "metadata": {},
   "source": [
    "#### Train Valid Test dataset\n",
    "##### Natural data (coco) train: 10000 // valid: 2900 // test: 1500\n",
    "##### Generated data (coco captions) train: 10000 (Augneted 3000, generated 7000) // valid: 2900 // test: 1500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7001\n"
     ]
    }
   ],
   "source": [
    "folder_path = './data/generated_images/train'\n",
    "files = os.listdir(folder_path)\n",
    "print(len(files))\n",
    "#files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the data structure\n",
    "data = {\n",
    "    'id': [],\n",
    "    'path': [],\n",
    "    'label': [],\n",
    "    'type': []  # Distinguishing between train, valid, and test\n",
    "}\n",
    "\n",
    "# Define the base directory\n",
    "base_dir = './data'\n",
    "\n",
    "# Define the subdirectories and labels\n",
    "categories = {\n",
    "    'generated_images': 'generated',\n",
    "    'natural_images': 'natural'\n",
    "}\n",
    "\n",
    "# Include 'test' in the subfolders\n",
    "subfolders = ['train', 'valid', 'test']\n",
    "\n",
    "# Function to process each directory\n",
    "def process_directory(path, label, folder_type):\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        # Only proceed if in the right subfolder\n",
    "        if os.path.basename(root) in subfolders:\n",
    "            for file in files:\n",
    "                if file.lower().endswith(('.png', '.jpg', '.jpeg')):  # Adjust for image formats as necessary\n",
    "                    data['id'].append(file)\n",
    "                    data['path'].append(os.path.join(root, file))\n",
    "                    data['label'].append(label)\n",
    "                    data['type'].append(folder_type)\n",
    "\n",
    "# Iterate through each category and its specified subdirectories\n",
    "for category, label in categories.items():\n",
    "    for subfolder in subfolders:\n",
    "        dir_path = os.path.join(base_dir, category, subfolder)\n",
    "        process_directory(dir_path, label, subfolder)\n",
    "\n",
    "# Convert the entire data to a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "le = preprocessing.LabelEncoder()\n",
    "df['label'] = le.fit_transform(df['label'].values)\n",
    "\n",
    "# Creating separate dataframes for train, valid, and test\n",
    "df_train = df[df['type'] == 'train'].reset_index(drop=True)\n",
    "df_valid = df[df['type'] == 'valid'].reset_index(drop=True)\n",
    "df_test = df[df['type'] == 'test'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>path</th>\n",
       "      <th>label</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>folder2_05076.png</td>\n",
       "      <td>./data/generated_images/valid/folder2_05076.png</td>\n",
       "      <td>0</td>\n",
       "      <td>valid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>folder2_02580.png</td>\n",
       "      <td>./data/generated_images/valid/folder2_02580.png</td>\n",
       "      <td>0</td>\n",
       "      <td>valid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>folder1_01296.png</td>\n",
       "      <td>./data/generated_images/valid/folder1_01296.png</td>\n",
       "      <td>0</td>\n",
       "      <td>valid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>folder1_04224.png</td>\n",
       "      <td>./data/generated_images/valid/folder1_04224.png</td>\n",
       "      <td>0</td>\n",
       "      <td>valid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>folder2_02295.png</td>\n",
       "      <td>./data/generated_images/valid/folder2_02295.png</td>\n",
       "      <td>0</td>\n",
       "      <td>valid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5795</th>\n",
       "      <td>000000421602.jpg</td>\n",
       "      <td>./data/natural_images/valid/000000421602.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>valid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5796</th>\n",
       "      <td>000000183435.jpg</td>\n",
       "      <td>./data/natural_images/valid/000000183435.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>valid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5797</th>\n",
       "      <td>000000133436.jpg</td>\n",
       "      <td>./data/natural_images/valid/000000133436.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>valid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5798</th>\n",
       "      <td>000000447520.jpg</td>\n",
       "      <td>./data/natural_images/valid/000000447520.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>valid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5799</th>\n",
       "      <td>000000029358.jpg</td>\n",
       "      <td>./data/natural_images/valid/000000029358.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>valid</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5800 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id                                             path  \\\n",
       "0     folder2_05076.png  ./data/generated_images/valid/folder2_05076.png   \n",
       "1     folder2_02580.png  ./data/generated_images/valid/folder2_02580.png   \n",
       "2     folder1_01296.png  ./data/generated_images/valid/folder1_01296.png   \n",
       "3     folder1_04224.png  ./data/generated_images/valid/folder1_04224.png   \n",
       "4     folder2_02295.png  ./data/generated_images/valid/folder2_02295.png   \n",
       "...                 ...                                              ...   \n",
       "5795   000000421602.jpg     ./data/natural_images/valid/000000421602.jpg   \n",
       "5796   000000183435.jpg     ./data/natural_images/valid/000000183435.jpg   \n",
       "5797   000000133436.jpg     ./data/natural_images/valid/000000133436.jpg   \n",
       "5798   000000447520.jpg     ./data/natural_images/valid/000000447520.jpg   \n",
       "5799   000000029358.jpg     ./data/natural_images/valid/000000029358.jpg   \n",
       "\n",
       "      label   type  \n",
       "0         0  valid  \n",
       "1         0  valid  \n",
       "2         0  valid  \n",
       "3         0  valid  \n",
       "4         0  valid  \n",
       "...     ...    ...  \n",
       "5795      1  valid  \n",
       "5796      1  valid  \n",
       "5797      1  valid  \n",
       "5798      1  valid  \n",
       "5799      1  valid  \n",
       "\n",
       "[5800 rows x 4 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>path</th>\n",
       "      <th>label</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>folder2_03497.png</td>\n",
       "      <td>./data/generated_images/train/folder2_03497.png</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>folder2_02183.png</td>\n",
       "      <td>./data/generated_images/train/folder2_02183.png</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>folder1_06745.png</td>\n",
       "      <td>./data/generated_images/train/folder1_06745.png</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>folder1_05603.png</td>\n",
       "      <td>./data/generated_images/train/folder1_05603.png</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>folder2_02777.png</td>\n",
       "      <td>./data/generated_images/train/folder2_02777.png</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16995</th>\n",
       "      <td>000000326064.jpg</td>\n",
       "      <td>./data/natural_images/train/000000326064.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16996</th>\n",
       "      <td>000000205000.jpg</td>\n",
       "      <td>./data/natural_images/train/000000205000.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16997</th>\n",
       "      <td>000000219739.jpg</td>\n",
       "      <td>./data/natural_images/train/000000219739.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16998</th>\n",
       "      <td>000000462164.jpg</td>\n",
       "      <td>./data/natural_images/train/000000462164.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16999</th>\n",
       "      <td>000000269788.jpg</td>\n",
       "      <td>./data/natural_images/train/000000269788.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id                                             path  \\\n",
       "0      folder2_03497.png  ./data/generated_images/train/folder2_03497.png   \n",
       "1      folder2_02183.png  ./data/generated_images/train/folder2_02183.png   \n",
       "2      folder1_06745.png  ./data/generated_images/train/folder1_06745.png   \n",
       "3      folder1_05603.png  ./data/generated_images/train/folder1_05603.png   \n",
       "4      folder2_02777.png  ./data/generated_images/train/folder2_02777.png   \n",
       "...                  ...                                              ...   \n",
       "16995   000000326064.jpg     ./data/natural_images/train/000000326064.jpg   \n",
       "16996   000000205000.jpg     ./data/natural_images/train/000000205000.jpg   \n",
       "16997   000000219739.jpg     ./data/natural_images/train/000000219739.jpg   \n",
       "16998   000000462164.jpg     ./data/natural_images/train/000000462164.jpg   \n",
       "16999   000000269788.jpg     ./data/natural_images/train/000000269788.jpg   \n",
       "\n",
       "       label   type  \n",
       "0          0  train  \n",
       "1          0  train  \n",
       "2          0  train  \n",
       "3          0  train  \n",
       "4          0  train  \n",
       "...      ...    ...  \n",
       "16995      1  train  \n",
       "16996      1  train  \n",
       "16997      1  train  \n",
       "16998      1  train  \n",
       "16999      1  train  \n",
       "\n",
       "[17000 rows x 4 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8e34f5cf",
   "metadata": {},
   "source": [
    "#### Wandb (Trainning log tracking) init, project name define "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "581a512e",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_now = dt.datetime.now()\n",
    "run_id = time_now.strftime(\"%Y%m%d%H%M\")\n",
    "project_name = 'gen_'+ 'icp_res'\n",
    "user = 'hojunking'\n",
    "run_name = project_name + '_' + run_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6c454bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f5d2c6fd",
   "metadata": {},
   "source": [
    "##### All images have been augmented physically, only transform the images to be resized by 256 by 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "884eb987-4341-4fe7-8094-6e61cb051af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = A.Compose(\n",
    "    [\n",
    "        A.Resize(height = CFG['img_size'], width = CFG['img_size']),\n",
    "        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "        A.pytorch.transforms.ToTensorV2()\n",
    "    ])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6c6e59ad",
   "metadata": {},
   "source": [
    "#### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5f1561be",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, df, transform=None, output_label=True):\n",
    "        super().__init__()\n",
    "        self.df = df.reset_index(drop=True).copy()\n",
    "        self.transform = transform\n",
    "        self.output_label = output_label\n",
    "        \n",
    "        if output_label:\n",
    "            self.labels = self.df['label'].values\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "    \n",
    "    def __getitem__(self, index: int):\n",
    "        # Constructing the image path directly from the DataFrame\n",
    "        img_path = self.df.loc[index, 'path']\n",
    "        im_bgr = cv2.imread(img_path)\n",
    "        \n",
    "        # Check if image is loaded successfully\n",
    "        if im_bgr is not None:\n",
    "            img = cv2.cvtColor(im_bgr, cv2.COLOR_BGR2RGB)\n",
    "        else:\n",
    "            # If the image is not successfully loaded, create a black image of the defined size\n",
    "            img = np.zeros([CFG['img_size'], CFG['img_size'], 3], dtype=np.uint8)\n",
    "\n",
    "        # Crop the image from the center\n",
    "        min_side = min(img.shape[:2])\n",
    "        center_crop = A.Compose([\n",
    "            A.CenterCrop(height=min_side, width=min_side),  # Crop the center to the target size\n",
    "        ])\n",
    "        cropped_image = center_crop(image=img)[\"image\"]\n",
    "\n",
    "        # Apply transformations\n",
    "        if self.transform:\n",
    "            transformed_img = self.transform(image=cropped_image)['image']\n",
    "        else:\n",
    "            transformed_img = cropped_image\n",
    "        \n",
    "        # Get labels\n",
    "        if self.output_label:\n",
    "            target = self.labels[index]\n",
    "            return transformed_img, target\n",
    "        else:\n",
    "            return transformed_img\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "812ba765",
   "metadata": {},
   "source": [
    "#### Model Define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b1601bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class baseModel(nn.Module):\n",
    "    def __init__(self, model_arch, n_class=2, pretrained=False):\n",
    "        super().__init__()\n",
    "        self.model = timm.create_model(model_arch, pretrained=pretrained, num_classes=n_class)\n",
    "        # n_features = self.model.classifier.in_features\n",
    "        # self.model.classifier = nn.Linear(n_features, n_class)\n",
    "    \n",
    "    def freezing(self, freeze=False, trainable_layer=2):\n",
    "        if freeze:\n",
    "            # Freeze all parameters first\n",
    "            for param in self.model.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "            # Unfreeze the last few layers\n",
    "            if hasattr(self.model, 'features'):  # for models with 'features' block\n",
    "                for param in self.model.features[-trainable_layer:].parameters():\n",
    "                    param.requires_grad = True\n",
    "\n",
    "            if hasattr(self.model, 'classifier'):  # for models with 'classifier' block\n",
    "                for param in self.model.classifier.parameters():\n",
    "                    param.requires_grad = True \n",
    "            \n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "37bd9a51",
   "metadata": {},
   "source": [
    "##### Define Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "240e5531",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataloader(df_train, df_valid):\n",
    "    \n",
    "    train_ds = CustomDataset(df_train, transform=transform, output_label=True)\n",
    "    valid_ds = CustomDataset(df_valid, transform=transform,  output_label=True)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_ds,\n",
    "        batch_size=CFG['train_bs'],\n",
    "        pin_memory=True,\n",
    "        drop_last=False,\n",
    "        shuffle=True,\n",
    "        num_workers=CFG['num_workers'],\n",
    "    )\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        valid_ds, \n",
    "        batch_size=CFG['valid_bs'],\n",
    "        num_workers=CFG['num_workers'],\n",
    "        shuffle=False,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5014d065-a6ad-45f9-aee8-d1adb9da52b4",
   "metadata": {},
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "18d62956-1ab7-4c53-ad80-05955c3367f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(epoch, model, loss_fn, optimizer, train_loader, device, scheduler=None):\n",
    "    t = time.time()\n",
    "    model.train()  # Set model to training mode\n",
    "\n",
    "    running_loss = 0\n",
    "    image_preds_all = []\n",
    "    image_targets_all = []\n",
    "    \n",
    "    pbar = tqdm(enumerate(train_loader), total=len(train_loader))\n",
    "    for step, (imgs, image_labels) in pbar:\n",
    "        imgs, image_labels = imgs.to(device).float(), image_labels.to(device).long()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        with torch.cuda.amp.autocast():\n",
    "            image_preds = model(imgs)  # forward pass\n",
    "            loss = loss_fn(image_preds, image_labels)\n",
    "            scaler.scale(loss).backward()  # backward pass with scaled loss\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "        running_loss = 0.99 * running_loss + 0.01 * loss.item()  # update running loss\n",
    "        \n",
    "        # Update pbar description\n",
    "        pbar.set_description(f'Epoch {epoch} Loss: {running_loss:.4f}')\n",
    "        \n",
    "        image_preds_all.append(torch.argmax(image_preds, 1).detach().cpu().numpy())\n",
    "        image_targets_all.append(image_labels.detach().cpu().numpy())\n",
    "        \n",
    "    if scheduler is not None:\n",
    "        scheduler.step()\n",
    "\n",
    "    image_preds_all = np.concatenate(image_preds_all)\n",
    "    image_targets_all = np.concatenate(image_targets_all)\n",
    "    \n",
    "    accuracy = np.mean(image_preds_all == image_targets_all)\n",
    "    epoch_f1 = f1_score(image_targets_all, image_preds_all, average='macro')\n",
    "    \n",
    "    return image_preds_all, accuracy, running_loss / len(train_loader), confusion_matrix(image_targets_all, image_preds_all), epoch_f1\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fb18acac-bdc4-476d-91c3-50fd46b4f1db",
   "metadata": {},
   "source": [
    "##### Valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "28ed3ba1-8c45-4e70-b80a-5a26d11cdd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_one_epoch(epoch, model, loss_fn, val_loader, device, scheduler=None, schd_loss_update=False):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "\n",
    "    loss_sum = 0\n",
    "    image_preds_all = []\n",
    "    image_targets_all = []\n",
    "    \n",
    "    pbar = tqdm(enumerate(val_loader), total=len(val_loader))\n",
    "    with torch.no_grad():  # No gradients needed for validation\n",
    "        for step, (imgs, image_labels) in pbar:\n",
    "            imgs, image_labels = imgs.to(device).float(), image_labels.to(device).long()\n",
    "            \n",
    "            image_preds = model(imgs)  # forward pass\n",
    "            loss = loss_fn(image_preds, image_labels)  # calculate loss\n",
    "\n",
    "            # Aggregate predictions and targets for metrics calculation\n",
    "            image_preds_all.append(torch.argmax(image_preds, 1).detach().cpu().numpy())\n",
    "            image_targets_all.append(image_labels.detach().cpu().numpy())\n",
    "\n",
    "            loss_sum += loss.item() * image_labels.shape[0]  # total loss for average calculation\n",
    "            \n",
    "            # Update pbar description\n",
    "            pbar.set_description(f'Epoch {epoch} Loss: {loss_sum/((step+1) * val_loader.batch_size):.4f}')\n",
    "    \n",
    "    # Convert list of arrays to single numpy array for metric calculation\n",
    "    image_preds_all = np.concatenate(image_preds_all)\n",
    "    image_targets_all = np.concatenate(image_targets_all)\n",
    "    \n",
    "    # Calculate performance metrics\n",
    "    epoch_f1 = f1_score(image_targets_all, image_preds_all, average='macro')\n",
    "    acc = np.mean(image_preds_all == image_targets_all)\n",
    "    val_loss = loss_sum / len(image_targets_all)  # average loss\n",
    "\n",
    "    # Step the scheduler if it's based on validation loss and such option is enabled\n",
    "    if scheduler is not None and schd_loss_update:\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "    return image_preds_all, acc, val_loss, confusion_matrix(image_targets_all, image_preds_all), epoch_f1\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "253e9ae3",
   "metadata": {},
   "source": [
    "##### Define EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "77e9950b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=10, verbose=False, delta=0):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf  # Initialize this to a large number\n",
    "        self.delta = delta\n",
    "\n",
    "    def __call__(self, val_loss):\n",
    "        score = -val_loss  # Convert to a score (as lower loss is better, we negate it)\n",
    "\n",
    "        if self.verbose:\n",
    "            print(f'Validation loss: {val_loss}')\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.val_loss_min = val_loss\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "                print(f'Best validation loss: {self.val_loss_min}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.val_loss_min = val_loss  # Update the minimum validation loss\n",
    "            self.counter = 0  # Reset counter\n",
    "\n",
    "        return self.early_stop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "37102a34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:4tz32gui) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Train Accuracy</td><td>▁▇███████</td></tr><tr><td>Train F1</td><td>▁▇███████</td></tr><tr><td>Train Loss</td><td>█▂▂▁▁▁▁▁▁</td></tr><tr><td>Valid Accuracy</td><td>▅▆▅▁▇▇█▇▆</td></tr><tr><td>Valid F1</td><td>▅▆▅▁▇▇█▇▆</td></tr><tr><td>Valid Loss</td><td>▂▂▂█▂▁▁▁▃</td></tr><tr><td>epoch</td><td>▁▁▂▂▃▃▄▄▅▅▅▅▆▆▇▇██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Train Accuracy</td><td>0.99953</td></tr><tr><td>Train F1</td><td>0.99951</td></tr><tr><td>Train Loss</td><td>1e-05</td></tr><tr><td>Valid Accuracy</td><td>0.97672</td></tr><tr><td>Valid F1</td><td>0.97672</td></tr><tr><td>Valid Loss</td><td>0.07798</td></tr><tr><td>epoch</td><td>8</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">apricot-energy-2</strong> at: <a href='https://wandb.ai/hojunking/gen_icp_res/runs/4tz32gui' target=\"_blank\">https://wandb.ai/hojunking/gen_icp_res/runs/4tz32gui</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231226_211344-4tz32gui/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:4tz32gui). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/knuvi/Desktop/hojun/generated_image_classifier/wandb/run-20231226_214831-ma629hvu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/hojunking/gen_icp_res/runs/ma629hvu' target=\"_blank\">woven-voice-3</a></strong> to <a href='https://wandb.ai/hojunking/gen_icp_res' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/hojunking/gen_icp_res' target=\"_blank\">https://wandb.ai/hojunking/gen_icp_res</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/hojunking/gen_icp_res/runs/ma629hvu' target=\"_blank\">https://wandb.ai/hojunking/gen_icp_res/runs/ma629hvu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: resnet50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model.safetensors: 100%|██████████| 102M/102M [00:10<00:00, 9.91MB/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0 Loss: 0.3038: 100%|██████████| 133/133 [01:47<00:00,  1.24it/s]\n",
      "Epoch 0 Loss: 0.2280: 100%|██████████| 91/91 [00:40<00:00,  2.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0], Train Loss : [0.00228] Val Loss : [0.22894] Val F1 Score : [0.94551]\n",
      "Validation loss: 0.9455083711010746\n",
      "time : 0:02:27\n",
      "Best Train Marco F1 : 0.71465\n",
      "[[3160 3840]\n",
      " [ 291 9709]]\n",
      "Best Valid Marco F1 : 0.94551\n",
      "[[2705  195]\n",
      " [ 121 2779]]\n",
      "Epoch 1/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 0.0838: 100%|██████████| 133/133 [01:45<00:00,  1.27it/s]\n",
      "Epoch 1 Loss: 0.1087: 100%|██████████| 91/91 [00:39<00:00,  2.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1], Train Loss : [0.00063] Val Loss : [0.10916] Val F1 Score : [0.95858]\n",
      "Validation loss: 0.95857529487724\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Best validation loss: 0.9455083711010746\n",
      "time : 0:04:53\n",
      "Best Train Marco F1 : 0.95889\n",
      "[[6690  310]\n",
      " [ 368 9632]]\n",
      "Best Valid Marco F1 : 0.95858\n",
      "[[2876   24]\n",
      " [ 216 2684]]\n",
      "Epoch 2/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 Loss: 0.0438: 100%|██████████| 133/133 [01:45<00:00,  1.26it/s]\n",
      "Epoch 2 Loss: 0.0666:  62%|██████▏   | 56/91 [00:32<00:06,  5.16it/s]"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    seed_everything(CFG['seed'])\n",
    "    \n",
    "    # WANDB TRACKER INIT\n",
    "    wandb.init(project=project_name, entity=user)\n",
    "    wandb.config.update(CFG)\n",
    "    wandb.run.name = run_name\n",
    "    wandb.define_metric(\"Train Accuracy\", step_metric=\"epoch\")\n",
    "    wandb.define_metric(\"Valid Accuracy\", step_metric=\"epoch\")\n",
    "    wandb.define_metric(\"Train Loss\", step_metric=\"epoch\")\n",
    "    wandb.define_metric(\"Valid Loss\", step_metric=\"epoch\")\n",
    "    wandb.define_metric(\"Train Macro F1 Score\", step_metric=\"epoch\")\n",
    "    wandb.define_metric(\"Valid Macro F1 Score\", step_metric=\"epoch\")\n",
    "    wandb.define_metric(\"Train-Valid Accuracy\", step_metric=\"epoch\")\n",
    "    \n",
    "    model_dir = CFG['model_path'] + '/{}'.format(run_name)\n",
    "    best_f1 =0.0\n",
    "    print('Model: {}'.format(CFG['model']))\n",
    "    # MAKE MODEL DIR\n",
    "    if not os.path.isdir(model_dir):\n",
    "        os.makedirs(model_dir)\n",
    "    \n",
    "    # EARLY STOPPING DEFINITION\n",
    "    early_stopping = EarlyStopping(patience=CFG[\"patience\"], verbose=True)\n",
    "\n",
    "    # DATALOADER DEFINITION\n",
    "    train_loader, val_loader = prepare_dataloader(df_train, df_valid)\n",
    "\n",
    "    # MODEL & DEVICE DEFINITION \n",
    "    device = torch.device(CFG['device'])\n",
    "    model =baseModel(CFG['model'], df_train.label.nunique(), pretrained=True)\n",
    "    \n",
    "    # MODEL FREEZING\n",
    "    #model.freezing(freeze = CFG['freezing'], trainable_layer = CFG['trainable_layer'])\n",
    "    if CFG['freezing'] ==True:\n",
    "        for name, param in model.named_parameters():\n",
    "            if param.requires_grad == True:\n",
    "                print(f\"{name}: {param.requires_grad}\")\n",
    "\n",
    "    model.to(device)\n",
    "    # MODEL DATA PARALLEL\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        model = nn.DataParallel(model)\n",
    "\n",
    "    scaler = torch.cuda.amp.GradScaler()   \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=CFG['lr'])\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, gamma=0.5, step_size=5)\n",
    "\n",
    "    # CRITERION (LOSS FUNCTION)\n",
    "    loss_tr = nn.CrossEntropyLoss().to(device) #MyCrossEntropyLoss().to(device)\n",
    "    loss_fn = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "    wandb.watch(model, loss_tr, log='all')\n",
    "    train_acc_list = []\n",
    "    train_matrix_list = []\n",
    "    train_f1_list = []\n",
    "    valid_acc_list = []\n",
    "    valid_matrix_list = []\n",
    "    valid_f1_list = []\n",
    "    \n",
    "\n",
    "    start = time.time()\n",
    "    for epoch in range(CFG['epochs']):\n",
    "        print('Epoch {}/{}'.format(epoch, CFG['epochs'] - 1))\n",
    "\n",
    "        # TRAINIG\n",
    "        train_preds_all, train_acc, train_loss, train_matrix, train_f1 = train_one_epoch(epoch, model, loss_tr,\n",
    "                                                                    optimizer, train_loader, device, scheduler=scheduler)\n",
    "        wandb.log({'Train Accuracy':train_acc, 'Train Loss' : train_loss, 'Train F1': train_f1, 'epoch' : epoch})\n",
    "\n",
    "        # VALIDATION\n",
    "        with torch.no_grad():\n",
    "            valid_preds_all, valid_acc, valid_loss, valid_matrix, valid_f1= valid_one_epoch(epoch, model, loss_fn,\n",
    "                                                                    val_loader, device, scheduler=None)\n",
    "            wandb.log({'Valid Accuracy':valid_acc, 'Valid Loss' : valid_loss, 'Valid F1': valid_f1 ,'epoch' : epoch})\n",
    "        print(f'Epoch [{epoch}], Train Loss : [{train_loss :.5f}] Val Loss : [{valid_loss :.5f}] Val F1 Score : [{valid_f1:.5f}]')\n",
    "        \n",
    "        # SAVE ALL RESULTS\n",
    "        train_acc_list.append(train_acc)\n",
    "        train_matrix_list.append(train_matrix)\n",
    "        train_f1_list.append(train_f1)\n",
    "\n",
    "        valid_acc_list.append(valid_acc)\n",
    "        valid_matrix_list.append(valid_matrix)\n",
    "        valid_f1_list.append(valid_f1)\n",
    "\n",
    "        # MODEL SAVE (THE BEST MODEL OF ALL OF FOLD PROCESS)\n",
    "        if valid_f1 > best_f1:\n",
    "            best_f1 = valid_f1\n",
    "            best_epoch = epoch\n",
    "            # SAVE WITH DATAPARARELLEL WRAPPER\n",
    "            #torch.save(model.state_dict(), (model_dir+'/{}.pth').format(CFG['model']))\n",
    "            # SAVE WITHOUT DATAPARARELLEL WRAPPER\n",
    "            torch.save(model.module.state_dict(), (model_dir+'/{}.pth').format(CFG['model']))\n",
    "\n",
    "        # EARLY STOPPING\n",
    "        stop = early_stopping(valid_f1)\n",
    "        if stop:\n",
    "            print(\"stop called\")   \n",
    "            break\n",
    "\n",
    "        end = time.time() - start\n",
    "        time_ = str(datetime.timedelta(seconds=end)).split(\".\")[0]\n",
    "        print(\"time :\", time_)\n",
    "\n",
    "        # PRINT BEST F1 SCORE MODEL OF FOLD\n",
    "        best_index = valid_f1_list.index(max(valid_f1_list))\n",
    "        print(f'Best Train Marco F1 : {train_f1_list[best_index]:.5f}')\n",
    "        print(train_matrix_list[best_index])\n",
    "        print(f'Best Valid Marco F1 : {valid_f1_list[best_index]:.5f}')\n",
    "        print(valid_matrix_list[best_index])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "58fade31-3bfc-4d71-9d57-73779368c975",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "84cfa9f6-64a2-4f81-a093-714b8d4c05ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>path</th>\n",
       "      <th>label</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>folder1_01804.png</td>\n",
       "      <td>./data/generated_images/test/folder1_01804.png</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>folder1_01315.png</td>\n",
       "      <td>./data/generated_images/test/folder1_01315.png</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>folder1_03599.png</td>\n",
       "      <td>./data/generated_images/test/folder1_03599.png</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>folder2_03260.png</td>\n",
       "      <td>./data/generated_images/test/folder2_03260.png</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>folder1_02035.png</td>\n",
       "      <td>./data/generated_images/test/folder1_02035.png</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>000000531423.jpg</td>\n",
       "      <td>./data/natural_images/test/000000531423.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>000000204775.jpg</td>\n",
       "      <td>./data/natural_images/test/000000204775.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>000000412690.jpg</td>\n",
       "      <td>./data/natural_images/test/000000412690.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>000000545375.jpg</td>\n",
       "      <td>./data/natural_images/test/000000545375.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>000000334557.jpg</td>\n",
       "      <td>./data/natural_images/test/000000334557.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id                                            path  \\\n",
       "0     folder1_01804.png  ./data/generated_images/test/folder1_01804.png   \n",
       "1     folder1_01315.png  ./data/generated_images/test/folder1_01315.png   \n",
       "2     folder1_03599.png  ./data/generated_images/test/folder1_03599.png   \n",
       "3     folder2_03260.png  ./data/generated_images/test/folder2_03260.png   \n",
       "4     folder1_02035.png  ./data/generated_images/test/folder1_02035.png   \n",
       "...                 ...                                             ...   \n",
       "2995   000000531423.jpg     ./data/natural_images/test/000000531423.jpg   \n",
       "2996   000000204775.jpg     ./data/natural_images/test/000000204775.jpg   \n",
       "2997   000000412690.jpg     ./data/natural_images/test/000000412690.jpg   \n",
       "2998   000000545375.jpg     ./data/natural_images/test/000000545375.jpg   \n",
       "2999   000000334557.jpg     ./data/natural_images/test/000000334557.jpg   \n",
       "\n",
       "      label  type  \n",
       "0         0  test  \n",
       "1         0  test  \n",
       "2         0  test  \n",
       "3         0  test  \n",
       "4         0  test  \n",
       "...     ...   ...  \n",
       "2995      1  test  \n",
       "2996      1  test  \n",
       "2997      1  test  \n",
       "2998      1  test  \n",
       "2999      1  test  \n",
       "\n",
       "[3000 rows x 4 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5907038e-59c2-46f1-bdc5-ec3ed9655eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(model, data_loader, device):\n",
    "    model.eval()\n",
    "    image_preds_all = []\n",
    "\n",
    "    pbar = tqdm(enumerate(data_loader), total=len(data_loader), desc=\"Inference Batches\")\n",
    "    with torch.no_grad():  # No gradients needed for inference\n",
    "        for step, imgs in pbar:\n",
    "            imgs = imgs.to(device).float()\n",
    "\n",
    "            # Forward pass\n",
    "            image_preds = model(imgs)\n",
    "            # Apply softmax to calculate probabilities\n",
    "            image_preds_all.append(torch.softmax(image_preds, 1).detach().cpu().numpy())\n",
    "    \n",
    "    # Concatenate all batch predictions\n",
    "    image_preds_all = np.concatenate(image_preds_all, axis=0)\n",
    "    return image_preds_all\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2a1b54ea",
   "metadata": {},
   "source": [
    "##### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1ebad47d-74a3-433f-9309-b06b5acad047",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Batches: 100%|██████████| 24/24 [00:24<00:00,  1.00s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>path</th>\n",
       "      <th>label</th>\n",
       "      <th>type</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>folder1_01804.png</td>\n",
       "      <td>./data/generated_images/test/folder1_01804.png</td>\n",
       "      <td>generated</td>\n",
       "      <td>test</td>\n",
       "      <td>generated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>folder1_01315.png</td>\n",
       "      <td>./data/generated_images/test/folder1_01315.png</td>\n",
       "      <td>generated</td>\n",
       "      <td>test</td>\n",
       "      <td>generated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>folder1_03599.png</td>\n",
       "      <td>./data/generated_images/test/folder1_03599.png</td>\n",
       "      <td>generated</td>\n",
       "      <td>test</td>\n",
       "      <td>generated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>folder2_03260.png</td>\n",
       "      <td>./data/generated_images/test/folder2_03260.png</td>\n",
       "      <td>generated</td>\n",
       "      <td>test</td>\n",
       "      <td>generated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>folder1_02035.png</td>\n",
       "      <td>./data/generated_images/test/folder1_02035.png</td>\n",
       "      <td>generated</td>\n",
       "      <td>test</td>\n",
       "      <td>generated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>000000531423.jpg</td>\n",
       "      <td>./data/natural_images/test/000000531423.jpg</td>\n",
       "      <td>natural</td>\n",
       "      <td>test</td>\n",
       "      <td>natural</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>000000204775.jpg</td>\n",
       "      <td>./data/natural_images/test/000000204775.jpg</td>\n",
       "      <td>natural</td>\n",
       "      <td>test</td>\n",
       "      <td>natural</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>000000412690.jpg</td>\n",
       "      <td>./data/natural_images/test/000000412690.jpg</td>\n",
       "      <td>natural</td>\n",
       "      <td>test</td>\n",
       "      <td>generated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>000000545375.jpg</td>\n",
       "      <td>./data/natural_images/test/000000545375.jpg</td>\n",
       "      <td>natural</td>\n",
       "      <td>test</td>\n",
       "      <td>generated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>000000334557.jpg</td>\n",
       "      <td>./data/natural_images/test/000000334557.jpg</td>\n",
       "      <td>natural</td>\n",
       "      <td>test</td>\n",
       "      <td>natural</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id                                            path  \\\n",
       "0     folder1_01804.png  ./data/generated_images/test/folder1_01804.png   \n",
       "1     folder1_01315.png  ./data/generated_images/test/folder1_01315.png   \n",
       "2     folder1_03599.png  ./data/generated_images/test/folder1_03599.png   \n",
       "3     folder2_03260.png  ./data/generated_images/test/folder2_03260.png   \n",
       "4     folder1_02035.png  ./data/generated_images/test/folder1_02035.png   \n",
       "...                 ...                                             ...   \n",
       "2995   000000531423.jpg     ./data/natural_images/test/000000531423.jpg   \n",
       "2996   000000204775.jpg     ./data/natural_images/test/000000204775.jpg   \n",
       "2997   000000412690.jpg     ./data/natural_images/test/000000412690.jpg   \n",
       "2998   000000545375.jpg     ./data/natural_images/test/000000545375.jpg   \n",
       "2999   000000334557.jpg     ./data/natural_images/test/000000334557.jpg   \n",
       "\n",
       "          label  type       pred  \n",
       "0     generated  test  generated  \n",
       "1     generated  test  generated  \n",
       "2     generated  test  generated  \n",
       "3     generated  test  generated  \n",
       "4     generated  test  generated  \n",
       "...         ...   ...        ...  \n",
       "2995    natural  test    natural  \n",
       "2996    natural  test    natural  \n",
       "2997    natural  test  generated  \n",
       "2998    natural  test  generated  \n",
       "2999    natural  test    natural  \n",
       "\n",
       "[3000 rows x 5 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the model with the right architecture and number of classes\n",
    "model = baseModel(CFG['model'], df_test.label.nunique(), pretrained=True)\n",
    "\n",
    "# Load the trained weights into the model\n",
    "load_model_path = CFG['model_path'] + '/gen_icp_res_202312262110/' + CFG['model'] + '.pth'\n",
    "model.load_state_dict(torch.load(load_model_path, map_location=device))\n",
    "\n",
    "# Prepare the test dataset and loader\n",
    "tst_ds = CustomDataset(df_test, transform=transform, output_label=False)\n",
    "tst_loader = torch.utils.data.DataLoader(\n",
    "    tst_ds, \n",
    "    batch_size=CFG['train_bs'],\n",
    "    num_workers=CFG['num_workers'],\n",
    "    shuffle=False,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "# Move the model to the appropriate device (CPU or GPU)\n",
    "model.to(device)\n",
    "\n",
    "# Wrap the model with DataParallel if using multiple GPUs\n",
    "if torch.cuda.device_count() > 1:\n",
    "    model = nn.DataParallel(model)\n",
    "\n",
    "# Run inference and collect predictions\n",
    "with torch.no_grad():\n",
    "    predictions = inference(model, tst_loader, device)\n",
    "\n",
    "# Assuming the task is a classification, convert softmax outputs to predicted class labels\n",
    "df_test['pred'] = np.argmax(predictions, axis=1)\n",
    "\n",
    "## Decode labels & Predictions\n",
    "df_test['label'] = le.inverse_transform(df_test['label'].values)\n",
    "df_test['pred'] = le.inverse_transform(df_test['pred'].values)\n",
    "df_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "dce5fb6e-174b-4276-bccb-4499b004243c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9790\n",
      "f1_score: 0.9790\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "test_acc = np.sum(df_test.label == df_test.pred) / len(df_test)\n",
    "test_matrix = confusion_matrix(df_test['label'], df_test['pred'])\n",
    "epoch_f1 = f1_score(df_test['label'], df_test['pred'], average='macro')\n",
    "print(f'accuracy: {test_acc:.4f}')\n",
    "print(f'f1_score: {epoch_f1:.4f}')\n",
    "\n",
    "#test_matrix = confusion_matrix(df_test['label'], df_test['pred'], normalize='true')\n",
    "test_matrix = confusion_matrix(df_test['label'], df_test['pred'])\n",
    "\n",
    "plt.figure(figsize = (15,10))\n",
    "sns.heatmap(test_matrix, \n",
    "            annot=True, \n",
    "            xticklabels = sorted(set(df_test['label'])), \n",
    "            yticklabels = sorted(set(df_test['label'])),\n",
    "            )\n",
    "plt.title('Normalized Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "#print(f'confusion_matrix \\n-------------------------\\n {test_matrix}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "'a' cannot be empty unless no samples are taken",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/knuvi/Desktop/hojun/generated_image_classifier/train.ipynb Cell 33\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B155.230.90.69/home/knuvi/Desktop/hojun/generated_image_classifier/train.ipynb#X56sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39m# Select 5 random samples from each\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B155.230.90.69/home/knuvi/Desktop/hojun/generated_image_classifier/train.ipynb#X56sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mseed(\u001b[39m42\u001b[39m)  \u001b[39m# for reproducibility\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B155.230.90.69/home/knuvi/Desktop/hojun/generated_image_classifier/train.ipynb#X56sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m sample_TN \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mrandom\u001b[39m.\u001b[39;49mchoice(TN_indices, \u001b[39m5\u001b[39;49m, replace\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B155.230.90.69/home/knuvi/Desktop/hojun/generated_image_classifier/train.ipynb#X56sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m sample_FP \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mchoice(FP_indices, \u001b[39m5\u001b[39m, replace\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32mnumpy/random/mtrand.pyx:950\u001b[0m, in \u001b[0;36mnumpy.random.mtrand.RandomState.choice\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: 'a' cannot be empty unless no samples are taken"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Assuming df_test['true'] contains the true labels and df_test['pred'] contains the predicted labels\n",
    "true_labels = df_test['label'].values  # or however you have your true labels stored\n",
    "predicted_labels = df_test['pred'].values\n",
    "\n",
    "# Get confusion matrix\n",
    "cm = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "# Find indices of TN and FP\n",
    "TN_indices = np.where((predicted_labels == 0) & (true_labels == 0))[0]\n",
    "FP_indices = np.where((predicted_labels == 1) & (true_labels == 0))[0]\n",
    "\n",
    "# Select 5 random samples from each\n",
    "np.random.seed(42)  # for reproducibility\n",
    "sample_TN = np.random.choice(TN_indices, 5, replace=False)\n",
    "sample_FP = np.random.choice(FP_indices, 5, replace=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(indices, df):\n",
    "    images = []\n",
    "    for idx in indices:\n",
    "        img_path = df.loc[idx, 'path']  # Assuming 'path' column has the image paths\n",
    "        img = Image.open(img_path)\n",
    "        images.append(img)\n",
    "    return images\n",
    "\n",
    "# Load images\n",
    "TN_images = load_images(sample_TN, df_test)\n",
    "FP_images = load_images(sample_FP, df_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_images(images, title):\n",
    "    plt.figure(figsize=(15, 3))\n",
    "    for i, img in enumerate(images):\n",
    "        plt.subplot(1, 5, i + 1)\n",
    "        plt.imshow(img)\n",
    "        plt.title(f'{title} {i+1}')\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Plotting the results\n",
    "plot_images(TN_images, \"True Negative\")\n",
    "plot_images(FP_images, \"False Positive\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
